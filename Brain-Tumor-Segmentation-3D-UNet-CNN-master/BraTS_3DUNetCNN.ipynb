{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:37:19.755506Z",
     "start_time": "2018-06-19T23:37:17.107613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6473538139004387818\n",
      "]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from functools import partial\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.layers import Input, LeakyReLU, Add, UpSampling3D, Activation, SpatialDropout3D\n",
    "from keras.engine import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D, Flatten, Dense, GlobalAveragePooling3D\n",
    "\n",
    "# K.set_image_dim_ordering('th')\n",
    "K.set_image_data_format=='tf'\n",
    "K.set_image_data_format=='th'\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "try:\n",
    "    from keras.engine import merge\n",
    "except ImportError:\n",
    "    from keras.layers.merge import concatenate\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(len(device_lib.list_local_devices()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in survival data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:37:19.778795Z",
     "start_time": "2018-06-19T23:37:19.757500Z"
    }
   },
   "outputs": [],
   "source": [
    "survival_data = pd.read_csv('survival_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:40:16.711845Z",
     "start_time": "2018-06-19T23:40:16.706597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = 'BraTS19_CBICA_AAB_1'\n",
    "survival_data[survival_data.BraTS19ID==ID].Survival.astype(int).values.item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tumor type dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_type_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "HGG_dir_list = next(os.walk('C:/Users/user/Desktop/MICCAI_BraTS_2019_Data_Training/MICCAI_BraTS_2019_Data_Training/HGG/'))[1]\n",
    "# print(len(HGG_dir_list))\n",
    "LGG_dir_list = next(os.walk('C:/Users/user/Desktop/MICCAI_BraTS_2019_Data_Training/MICCAI_BraTS_2019_Data_Training/LGG/'))[1]\n",
    "# print(len(LGG_dir_list))\n",
    "\n",
    "\n",
    "for patientID in HGG_dir_list+LGG_dir_list:\n",
    "#     print(patientID)\n",
    "    if patientID in HGG_dir_list:\n",
    "#         tumor_type_dict[patientID] = \"HGG\"\n",
    "        tumor_type_dict[patientID] = 0\n",
    "    elif patientID in LGG_dir_list:\n",
    "#         tumor_type_dict[patientID] = \"LGG\"\n",
    "        tumor_type_dict[patientID] = 1\n",
    "\n",
    "print(len(tumor_type_dict))\n",
    "for patientID in HGG_dir_list+LGG_dir_list:\n",
    "    print(tumor_type_dict[patientID])\n",
    "# tumor_type_dict[(HGG_dir_list+LGG_dir_list)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return -dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def weighted_dice_coefficient(y_true, y_pred, axis=(-3, -2, -1), smooth=0.00001):\n",
    "    \"\"\"\n",
    "    Weighted dice coefficient. Default axis assumes a \"channels first\" data structure\n",
    "    :param smooth:\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param axis:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return K.mean(2. * (K.sum(y_true * y_pred,\n",
    "                              axis=axis) + smooth/2)/(K.sum(y_true,\n",
    "                                                            axis=axis) + K.sum(y_pred,\n",
    "                                                                               axis=axis) + smooth))\n",
    "\n",
    "\n",
    "def weighted_dice_coefficient_loss(y_true, y_pred):\n",
    "    return -weighted_dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def label_wise_dice_coefficient(y_true, y_pred, label_index):\n",
    "    return dice_coefficient(y_true[:, label_index], y_pred[:, label_index])\n",
    "\n",
    "\n",
    "def get_label_dice_coefficient_function(label_index):\n",
    "    f = partial(label_wise_dice_coefficient, label_index=label_index)\n",
    "    f.__setattr__('__name__', 'label_{0}_dice_coef'.format(label_index))\n",
    "    return f\n",
    "\n",
    "\n",
    "dice_coef = dice_coefficient\n",
    "dice_coef_loss = dice_coefficient_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T15:26:01.192753Z",
     "start_time": "2018-06-16T15:25:59.659294Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=None,\n",
    "                             padding='same', strides=(1, 1, 1), instance_normalization=False):\n",
    "    \"\"\"\n",
    "    :param strides:\n",
    "    :param input_layer:\n",
    "    :param n_filters:\n",
    "    :param batch_normalization:\n",
    "    :param kernel:\n",
    "    :param activation: Keras activation layer to use. (default is 'relu')\n",
    "    :param padding:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "    elif instance_normalization:\n",
    "        try:\n",
    "            from keras_contrib.layers.normalization import InstanceNormalization\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n",
    "                              \"\\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git\")\n",
    "        layer = InstanceNormalization(axis=1)(layer)\n",
    "    if activation is None:\n",
    "        return Activation('relu')(layer)\n",
    "    else:\n",
    "        return activation()(layer)\n",
    "\n",
    "\n",
    "def compute_level_output_shape(n_filters, depth, pool_size, image_shape):\n",
    "    \"\"\"\n",
    "    Each level has a particular output shape based on the number of filters used in that level and the depth or number \n",
    "    of max pooling operations that have been done on the data at that point.\n",
    "    :param image_shape: shape of the 3d image.\n",
    "    :param pool_size: the pool_size parameter used in the max pooling operation.\n",
    "    :param n_filters: Number of filters used by the last node in a given level.\n",
    "    :param depth: The number of levels down in the U-shaped model a given node is.\n",
    "    :return: 5D vector of the shape of the output node \n",
    "    \"\"\"\n",
    "    output_image_shape = np.asarray(np.divide(image_shape, np.power(pool_size, depth)), dtype=np.int32).tolist()\n",
    "    return tuple([None, n_filters] + output_image_shape)\n",
    "\n",
    "\n",
    "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                       deconvolution=False):\n",
    "    if deconvolution:\n",
    "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
    "                               strides=strides)\n",
    "    else:\n",
    "        return UpSampling3D(size=pool_size)\n",
    "\n",
    "def create_localization_module(input_layer, n_filters):\n",
    "    convolution1 = create_convolution_block(input_layer, n_filters)\n",
    "    convolution2 = create_convolution_block(convolution1, n_filters, kernel=(1, 1, 1))\n",
    "    return convolution2\n",
    "\n",
    "\n",
    "def create_up_sampling_module(input_layer, n_filters, size=(2, 2, 2)):\n",
    "    up_sample = UpSampling3D(size=size)(input_layer)\n",
    "    convolution = create_convolution_block(up_sample, n_filters)\n",
    "    return convolution\n",
    "\n",
    "\n",
    "def create_context_module(input_layer, n_level_filters, dropout_rate=0.3, data_format=\"channels_first\"):\n",
    "    convolution1 = create_convolution_block(input_layer=input_layer, n_filters=n_level_filters)\n",
    "    dropout = SpatialDropout3D(rate=dropout_rate, data_format=data_format)(convolution1)\n",
    "    convolution2 = create_convolution_block(input_layer=dropout, n_filters=n_level_filters)\n",
    "    return convolution2\n",
    "\n",
    "\n",
    "create_convolution_block = partial(create_convolution_block, activation=LeakyReLU, instance_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T20:10:10.456092Z",
     "start_time": "2018-06-15T20:10:10.453503Z"
    }
   },
   "source": [
    "### Make the labels and test train dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T21:07:14.833644Z",
     "start_time": "2018-06-19T21:07:14.826791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n",
      "259\n"
     ]
    }
   ],
   "source": [
    "# from glob import glob\n",
    "# paths = glob('/Users/etheredgej/Desktop/MICCAI_BraTS17_Data_Training/train/HGG/*/')\n",
    "# print(paths)\n",
    "\n",
    "import os\n",
    "HGG_dir_list = next(os.walk('C:/Users/user/Desktop/MICCAI_BraTS_2019_Data_Training/MICCAI_BraTS_2019_Data_Training/HGG/'))[1]\n",
    "print(len(HGG_dir_list))\n",
    "LGG_dir_list = next(os.walk('C:/Users/user/Desktop/MICCAI_BraTS_2019_Data_Training/MICCAI_BraTS_2019_Data_Training/HGG/'))[1]\n",
    "print(len(LGG_dir_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary for all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completelist = HGG_dir_list + LGG_dir_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:05:37.233873Z",
     "start_time": "2018-06-19T22:05:37.228522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "308\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "completelist = HGG_dir_list + LGG_dir_list\n",
    "\n",
    "# completelist = list(survival_data.Brats17ID.copy())\n",
    "\n",
    "# print(completelist[0:4])\n",
    "np.random.shuffle(completelist) # shuffles in place\n",
    "# print(completelist[0:4])\n",
    "\n",
    "partition={}\n",
    "\n",
    "holdout_percentage=0.15\n",
    "partition['holdout']=completelist[0:int(len(completelist)*holdout_percentage)]\n",
    "trainlist=completelist[int(len(completelist)*holdout_percentage):len(completelist)]\n",
    "\n",
    "train_percentage=0.7\n",
    "partition['train']=trainlist[0:int(len(trainlist)*train_percentage)]\n",
    "partition['test']=trainlist[int(len(trainlist)*train_percentage):len(trainlist)]\n",
    "\n",
    "\n",
    "labels={}\n",
    "# HGG=0\n",
    "# LGG=1\n",
    "for directory in HGG_dir_list:\n",
    "    labels[directory]=0\n",
    "for directory in LGG_dir_list:\n",
    "    labels[directory]=1\n",
    "    \n",
    "print(len(partition['holdout']))\n",
    "print(len(partition['train']))\n",
    "print(len(partition['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary for the samples with survival data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:05:37.233873Z",
     "start_time": "2018-06-19T22:05:37.228522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "154\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "# completelist = HGG_dir_list + LGG_dir_list\n",
    "\n",
    "completelist = list(survival_data.BraTS19ID.copy())\n",
    "\n",
    "# print(completelist[0:4])\n",
    "np.random.shuffle(completelist) # shuffles in place\n",
    "# print(completelist[0:4])\n",
    "\n",
    "subpartition={}\n",
    "\n",
    "holdout_percentage=0.15\n",
    "subpartition['holdout']=completelist[0:int(len(completelist)*holdout_percentage)]\n",
    "trainlist=completelist[int(len(completelist)*holdout_percentage):len(completelist)]\n",
    "\n",
    "train_percentage=0.7\n",
    "subpartition['train']=trainlist[0:int(len(trainlist)*train_percentage)]\n",
    "subpartition['test']=trainlist[int(len(trainlist)*train_percentage):len(trainlist)]\n",
    "\n",
    "\n",
    "labels={}\n",
    "# HGG=0\n",
    "# LGG=1\n",
    "for directory in HGG_dir_list:\n",
    "    labels[directory]=0\n",
    "for directory in LGG_dir_list:\n",
    "    labels[directory]=1\n",
    "    \n",
    "print(len(subpartition['holdout']))\n",
    "print(len(subpartition['train']))\n",
    "print(len(subpartition['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(completelist)\n",
    "# len(survival_data.Brats17ID)\n",
    "# len(set.intersection(set(completelist),set(survival_data.Brats17ID)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop_img function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:08:13.825621Z",
     "start_time": "2018-06-19T03:08:12.703423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.image.image import check_niimg\n",
    "from nilearn.image.image import _crop_img_to as crop_img_to\n",
    "\n",
    "\n",
    "def crop_img(img, rtol=1e-8, copy=True, return_slices=False):\n",
    "    \"\"\"Crops img as much as possible\n",
    "    Will crop img, removing as many zero entries as possible\n",
    "    without touching non-zero entries. Will leave one voxel of\n",
    "    zero padding around the obtained non-zero area in order to\n",
    "    avoid sampling issues later on.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: Niimg-like object\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        img to be cropped.\n",
    "    rtol: float\n",
    "        relative tolerance (with respect to maximal absolute\n",
    "        value of the image), under which values are considered\n",
    "        negligeable and thus croppable.\n",
    "    copy: boolean\n",
    "        Specifies whether cropped data is copied or not.\n",
    "    return_slices: boolean\n",
    "        If True, the slices that define the cropped image will be returned.\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_img: image\n",
    "        Cropped version of the input image\n",
    "    \"\"\"\n",
    "\n",
    "    img = check_niimg(img)\n",
    "    data = img.get_data()\n",
    "    infinity_norm = max(-data.min(), data.max())\n",
    "    passes_threshold = np.logical_or(data < -rtol * infinity_norm,\n",
    "                                     data > rtol * infinity_norm)\n",
    "\n",
    "    if data.ndim == 4:\n",
    "        passes_threshold = np.any(passes_threshold, axis=-1)\n",
    "    coords = np.array(np.where(passes_threshold))\n",
    "    start = coords.min(axis=1)\n",
    "    end = coords.max(axis=1) + 1\n",
    "\n",
    "    # pad with one voxel to avoid resampling problems\n",
    "    start = np.maximum(start - 1, 0)\n",
    "    end = np.minimum(end + 1, data.shape[:3])\n",
    "\n",
    "    slices = [slice(s, e) for s, e in zip(start, end)]\n",
    "\n",
    "    if return_slices:\n",
    "        return slices\n",
    "\n",
    "    return crop_img_to(img, slices, copy=copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the cropped images as pickled numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "\n",
    "# for i, ID in enumerate(completelist):\n",
    "\n",
    "#     img1 = './data/' + ID + '_flair.nii.gz'\n",
    "#     img2 = './data/' + ID + '_t1.nii.gz'\n",
    "#     img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "#     img4 = './data/' + ID + '_t2.nii.gz'\n",
    "#     img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "#     newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "#     cropped = crop_img(newimage)         \n",
    "#     img_array = np.array(cropped.dataobj)\n",
    "#     z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "#     padded_image = np.zeros((5,160,192,160))\n",
    "#     padded_image[:z.shape[0],:z.shape[1],:z.shape[2],:z.shape[3]] = z\n",
    "\n",
    "#     a,b,c,d,seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "#     images = np.concatenate([a,b,c,d], axis=0)\n",
    "\n",
    "#     # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "#     # split the channels:\n",
    "#     # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "#     seg_mask_1 = np.zeros((1,160,192,160))\n",
    "#     seg_mask_1[seg_mask.astype(int) == 1] = 1\n",
    "#     seg_mask_2 = np.zeros((1,160,192,160))\n",
    "#     seg_mask_2[seg_mask.astype(int) == 2] = 1\n",
    "#     seg_mask_3 = np.zeros((1,160,192,160))\n",
    "#     seg_mask_3[seg_mask.astype(int) == 4] = 1\n",
    "#     seg_mask_3ch = np.concatenate([seg_mask_1,seg_mask_2,seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "#     # 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT) \n",
    "#     # The ET is described by areas that show hyper-intensity in T1Gd when compared to T1, but also when compared to “healthy” white matter in T1Gd. The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. The appearance of the necrotic (NCR) and the non-enhancing (NET) tumor core is typically hypo-intense in T1-Gd when compared to T1. The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "#     # The labels in the provided data are: \n",
    "#     # 1 for NCR & NET (necrotic (NCR) and the non-enhancing (NET) tumor core) = TC (\"tumor core\")\n",
    "#     # 2 for ED (\"peritumoral edema\")\n",
    "#     # 4 for ET (\"enhancing tumor\")\n",
    "#     # 0 for everything else\n",
    "\n",
    "# #     X[i,] = images\n",
    "# #     y1[i,] = seg_mask_3ch\n",
    "#     pickle.dump( images, open( \"./data/%s_images.pkl\"%(ID), \"wb\" ) )\n",
    "#     pickle.dump( seg_mask_3ch, open( \"./data/%s_seg_mask_3ch.pkl\"%(ID), \"wb\" ) )\n",
    "#     print(\"Saving\", i+1, \"of\", len(completelist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator all samples (1 predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:12:14.451690Z",
     "start_time": "2018-06-16T16:12:14.441564Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import nibabel as nib\n",
    "\n",
    "class SingleDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=2, dim=(240,240,155), n_channels=4,\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y1 = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.n_channels, *self.dim))\n",
    "        y1 = np.empty((self.batch_size, 3, *self.dim))\n",
    "\n",
    "        # Generate data\n",
    "        # Decode and load the data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            # 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT) \n",
    "            # The ET is described by areas that show hyper-intensity in T1Gd when compared to T1, but also when compared to “healthy” white matter in T1Gd. The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. The appearance of the necrotic (NCR) and the non-enhancing (NET) tumor core is typically hypo-intense in T1-Gd when compared to T1. The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "            # The labels in the provided data are: \n",
    "            # 1 for NCR & NET (necrotic (NCR) and the non-enhancing (NET) tumor core) = TC (\"tumor core\")\n",
    "            # 2 for ED (\"peritumoral edema\")\n",
    "            # 4 for ET (\"enhancing tumor\")\n",
    "            # 0 for everything else\n",
    "\n",
    "            X[i,] = pickle.load( open( \"./data/%s_images.pkl\"%(ID), \"rb\" ) )\n",
    "            y1[i,] = pickle.load( open( \"./data/%s_seg_mask_3ch.pkl\"%(ID), \"rb\" ) )\n",
    "            \n",
    "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        return X, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator all samples (2 predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:12:14.451690Z",
     "start_time": "2018-06-16T16:12:14.441564Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import nibabel as nib\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=2, dim=(240,240,155), n_channels=4,\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y1, y2 = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, [y1, y2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.n_channels, *self.dim))\n",
    "        y1 = np.empty((self.batch_size, 3, *self.dim))\n",
    "        y2 = np.empty(self.batch_size)\n",
    "#         y2 = list()\n",
    "\n",
    "        # Generate data\n",
    "        # Decode and load the data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            # 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT) \n",
    "            # The ET is described by areas that show hyper-intensity in T1Gd when compared to T1, but also when compared to “healthy” white matter in T1Gd. The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. The appearance of the necrotic (NCR) and the non-enhancing (NET) tumor core is typically hypo-intense in T1-Gd when compared to T1. The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "            # The labels in the provided data are: \n",
    "            # 1 for NCR & NET (necrotic (NCR) and the non-enhancing (NET) tumor core) = TC (\"tumor core\")\n",
    "            # 2 for ED (\"peritumoral edema\")\n",
    "            # 4 for ET (\"enhancing tumor\")\n",
    "            # 0 for everything else\n",
    "\n",
    "            X[i,] = pickle.load( open( \"./data/%s_images.pkl\"%(ID), \"rb\" ) )\n",
    "            y1[i,] = pickle.load( open( \"./data/%s_seg_mask_3ch.pkl\"%(ID), \"rb\" ) )\n",
    "            y2[i,] = tumor_type_dict[ID]\n",
    "            \n",
    "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        return X, y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator for samples with survival data (3 predictions, subset of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:12:14.451690Z",
     "start_time": "2018-06-16T16:12:14.441564Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import nibabel as nib\n",
    "\n",
    "class SubDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=2, dim=(240,240,155), n_channels=4,\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y1, y2, y3 = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, [y1, y2, y3]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.n_channels, *self.dim))\n",
    "        y1 = np.empty((self.batch_size, 3, *self.dim))\n",
    "        y2 = np.empty(self.batch_size)\n",
    "        y3 = np.empty(self.batch_size)\n",
    "\n",
    "        # Generate data\n",
    "        # Decode and load the data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            # 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT) \n",
    "            # The ET is described by areas that show hyper-intensity in T1Gd when compared to T1, but also when compared to “healthy” white matter in T1Gd. The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. The appearance of the necrotic (NCR) and the non-enhancing (NET) tumor core is typically hypo-intense in T1-Gd when compared to T1. The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "            # The labels in the provided data are: \n",
    "            # 1 for NCR & NET (necrotic (NCR) and the non-enhancing (NET) tumor core) = TC (\"tumor core\")\n",
    "            # 2 for ED (\"peritumoral edema\")\n",
    "            # 4 for ET (\"enhancing tumor\")\n",
    "            # 0 for everything else\n",
    "\n",
    "            X[i,] = pickle.load( open( \"./data/%s_images.pkl\"%(ID), \"rb\" ) )\n",
    "            y1[i,] = pickle.load( open( \"./data/%s_seg_mask_3ch.pkl\"%(ID), \"rb\" ) )            \n",
    "            y2[i,] = tumor_type_dict[ID]\n",
    "            y3[i,] = survival_data[survival_data.Brats17ID==ID].Survival.astype(int).values.item(0)\n",
    "\n",
    "        return X, y1, y2, y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from my_classes import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = LGG_dir_list[0]\n",
    "type(tumor_type_dict[ID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single prediction compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:15:08.191305Z",
     "start_time": "2018-06-16T16:15:07.066321Z"
    }
   },
   "outputs": [],
   "source": [
    "# # change the number of labels?\n",
    "# # loss_function={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}\n",
    "# # selected_optimizer = RMSprop\n",
    "# # selected_initial_learning_rate = 5e-4\n",
    "\n",
    "# model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=12, depth=5, dropout_rate=0.3,\n",
    "#                       n_segmentation_levels=3, n_labels=3, activation_name=\"sigmoid\")\n",
    "\n",
    "# model.compile(optimizer=RMSprop(lr=5e-4), \n",
    "#               loss={'activation_block': weighted_dice_coefficient_loss}, \n",
    "#               loss_weights={'activation_block': 1.},\n",
    "#              metrics={'activation_block': ['accuracy',weighted_dice_coefficient, dice_coefficient]})\n",
    "\n",
    "# model.summary(line_length=150) # add the parameter that allows me to show everything instead of cutting it off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Install keras_contrib in order to use instance normalization.\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6376a17a0de5>\u001b[0m in \u001b[0;36mcreate_convolution_block\u001b[1;34m(input_layer, n_filters, batch_normalization, kernel, activation, padding, strides, instance_normalization)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'InstanceNormalization' from 'keras_contrib.layers.normalization' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_contrib\\layers\\normalization\\__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-bdf6d2621eab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcurrent_layer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0min_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_convolution_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_level_filters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0min_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_convolution_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_level_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6376a17a0de5>\u001b[0m in \u001b[0;36mcreate_convolution_block\u001b[1;34m(input_layer, n_filters, batch_normalization, kernel, activation, padding, strides, instance_normalization)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n\u001b[0m\u001b[0;32m     21\u001b[0m                               \"\\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git\")\n\u001b[0;32m     22\u001b[0m         \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Install keras_contrib in order to use instance normalization.\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git"
     ]
    }
   ],
   "source": [
    "# change the number of labels?\n",
    "# loss_function={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}\n",
    "# selected_optimizer = RMSprop\n",
    "# selected_initial_learning_rate = 5e-4\n",
    "#import keras_contrib\n",
    "#from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "input_shape=(4, 160, 192, 160)\n",
    "n_base_filters=12\n",
    "depth=5\n",
    "dropout_rate=0.3\n",
    "n_segmentation_levels=3\n",
    "n_labels=3\n",
    "activation_name=\"sigmoid\"\n",
    "\n",
    "\"\"\"\n",
    "This function builds a model proposed by Isensee et al. for the BRATS 2019 competition:\n",
    "https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/MICCAI_BraTS_2019_proceedings_shortPapers.pdf\n",
    "This network is highly similar to the model proposed by Kayalibay et al. \"CNN-based Segmentation of Medical\n",
    "Imaging Data\", 2019: https://arxiv.org/pdf/1701.03056.pdf\n",
    ":param input_shape:\n",
    ":param n_base_filters:\n",
    ":param depth:\n",
    ":param dropout_rate:\n",
    ":param n_segmentation_levels:\n",
    ":param n_labels:\n",
    ":param optimizer:\n",
    ":param initial_learning_rate:\n",
    ":param loss_function:\n",
    ":param activation_name:\n",
    ":return:\n",
    "\"\"\"\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "current_layer = inputs\n",
    "level_output_layers = list()\n",
    "level_filters = list()\n",
    "for level_number in range(depth):\n",
    "    n_level_filters = (2**level_number) * n_base_filters\n",
    "    level_filters.append(n_level_filters)\n",
    "\n",
    "    if current_layer is inputs:\n",
    "        in_conv = create_convolution_block(current_layer, n_level_filters)\n",
    "    else:\n",
    "        in_conv = create_convolution_block(current_layer, n_level_filters, strides=(2, 2, 2))\n",
    "\n",
    "    context_output_layer = create_context_module(in_conv, n_level_filters, dropout_rate=dropout_rate)\n",
    "\n",
    "    summation_layer = Add()([in_conv, context_output_layer])\n",
    "    level_output_layers.append(summation_layer)\n",
    "    current_layer = summation_layer\n",
    "\n",
    "segmentation_layers = list()\n",
    "for level_number in range(depth - 2, -1, -1):\n",
    "    up_sampling = create_up_sampling_module(current_layer, level_filters[level_number])\n",
    "    concatenation_layer = concatenate([level_output_layers[level_number], up_sampling], axis=1)\n",
    "    localization_output = create_localization_module(concatenation_layer, level_filters[level_number])\n",
    "    current_layer = localization_output\n",
    "    if level_number < n_segmentation_levels:\n",
    "        segmentation_layers.insert(0, create_convolution_block(current_layer, n_filters=n_labels, kernel=(1, 1, 1)))\n",
    "\n",
    "output_layer = None\n",
    "for level_number in reversed(range(n_segmentation_levels)):\n",
    "    segmentation_layer = segmentation_layers[level_number]\n",
    "    if output_layer is None:\n",
    "        output_layer = segmentation_layer\n",
    "    else:\n",
    "        output_layer = Add()([output_layer, segmentation_layer])\n",
    "\n",
    "    if level_number > 0:\n",
    "        output_layer = UpSampling3D(size=(2, 2, 2))(output_layer)\n",
    "\n",
    "activation_block = Activation(activation = activation_name, name='activation_block')(output_layer)\n",
    "#     survival_block = Activation(\"linear\")(summation_layer)\n",
    "#     activation_block = Dense(1, activation=activation_name, name='activation_block')(output_layer)\n",
    "#     flatten = Flatten(name='flatten')(summation_layer)\n",
    "#     survival_block = Dense(1, activation='linear', name='survival_block')(flatten)\n",
    "\n",
    "survival_conv_1 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_1')(summation_layer)\n",
    "survival_conv_2 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_2')(survival_conv_1)\n",
    "dropout = SpatialDropout3D(rate=dropout_rate, data_format='channels_first', name='dropout')(survival_conv_2)\n",
    "survival_conv_3 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_3')(dropout)\n",
    "survival_GAP = GlobalAveragePooling3D(name='survival_GAP')(survival_conv_3)\n",
    "#     flatten = Flatten(name='flatten')(survival_GAP)\n",
    "#     survival_block = Activation(\"linear\", name='survival_block')(flatten)\n",
    "survival_block = Dense(1, activation='linear', name='survival_block')(survival_GAP)\n",
    "\n",
    "tumortype_conv_1 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='tumortype_conv_1')(summation_layer)\n",
    "tumortype_conv_2 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='tumortype_conv_2')(tumortype_conv_1)\n",
    "tumortype_dropout = SpatialDropout3D(rate=dropout_rate, data_format='channels_first', name='tumortype_dropout')(tumortype_conv_2)\n",
    "tumortype_conv_3 = Conv3D(filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='tumortype_conv_3')(tumortype_dropout)\n",
    "tumortype_GAP = GlobalAveragePooling3D(name='tumortype_GAP')(tumortype_conv_3)\n",
    "#     flatten = Flatten(name='flatten')(tumortype_GAP)\n",
    "#     tumortype_block = Activation(\"linear\", name='tumortype_block')(flatten)\n",
    "tumortype_block = Dense(1, activation='sigmoid', name='tumortype_block')(tumortype_GAP)  \n",
    "\n",
    "model = Model(inputs=inputs, outputs=[activation_block])\n",
    "#     model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function)\n",
    "#     loss={'activation_block': 'binary_crossentropy', 'survival_block': 'mean_squared_error'}\n",
    "# assign weights and loss as dictionaries\n",
    "# functional-api-guide\n",
    "# loss_weights define the ratio of how much I care about optimizing each one\n",
    "\n",
    "model.load_weights(\"./weights/1pred_weights.25--0.08.hdf5\", by_name=True) # the by_name=True allows you to use a different architecture and bring in the weights from the matching layers \n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=5e-4), \n",
    "              loss={'activation_block': weighted_dice_coefficient_loss}, \n",
    "              loss_weights={'activation_block': 1.},\n",
    "             metrics={'activation_block': ['accuracy',weighted_dice_coefficient, dice_coefficient]})\n",
    "\n",
    "model.summary(line_length=150) # add the parameter that allows me to show everything instead of cutting it off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the 2 prediction full data net (1 prediction this time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:15:14.331Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = SingleDataGenerator(partition['train'], **params)\n",
    "validation_generator = SingleDataGenerator(partition['test'], **params)\n",
    "\n",
    "cb_1=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "cb_2=keras.callbacks.ModelCheckpoint(filepath=\"./weights/1Bpred_weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "results = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                   epochs=100, \n",
    "                   nb_worker=4,\n",
    "                   callbacks=[cb_1,cb_2])\n",
    "model.save_weights(\"./weights/model_1_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training history and predictions for 1 prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1_pred = results.history\n",
    "pickle.dump( history_1_pred, open( \"./weights/history_1_pred.pkl\", \"wb\" ) )\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = SingleDataGenerator(partition['holdout'], **params)\n",
    "\n",
    "predictions_1_pred = model.predict_generator(generator=validation_generator)\n",
    "\n",
    "pickle.dump( predictions_1_pred, open( \"./weights/predictions_1_pred.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 predictions compilation (all data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:15:08.191305Z",
     "start_time": "2018-06-16T16:15:07.066321Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=[activation_block,tumortype_block])\n",
    "model.load_weights(\"./weights/model_1_weights.h5\", by_name=True) # the by_name=True allows you to use a different architecture and bring in the weights from the matching layers \n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=5e-4), \n",
    "              loss={'activation_block': weighted_dice_coefficient_loss, 'tumortype_block': 'binary_crossentropy'}, \n",
    "              loss_weights={'activation_block': 1., 'tumortype_block': 0.2},\n",
    "             metrics={'activation_block': ['accuracy',weighted_dice_coefficient, dice_coefficient], 'tumortype_block': ['accuracy']})\n",
    "\n",
    "model.summary(line_length=150) # add the parameter that allows me to show everything instead of cutting it off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the 2 prediction full data net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:15:14.331Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], **params)\n",
    "validation_generator = DataGenerator(partition['test'], **params)\n",
    "\n",
    "cb_1=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "cb_2=keras.callbacks.ModelCheckpoint(filepath=\"./weights/2pred_weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "results = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                   epochs=100, \n",
    "                   nb_worker=4,\n",
    "                   callbacks=[cb_1,cb_2])\n",
    "\n",
    "model.save_weights(\"./weights/model_2_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training history and predictions for 2 predictions (all data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2_pred = results.history\n",
    "pickle.dump( history_2_pred, open( \"./weights/history_2_pred.pkl\", \"wb\" ) )\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = DataGenerator(partition['holdout'], **params)\n",
    "\n",
    "predictions_2_pred = model.predict_generator(generator=validation_generator)\n",
    "\n",
    "pickle.dump( predictions_2_pred, open( \"./weights/predictions_2_pred.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 predictions compilation (all data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:15:08.191305Z",
     "start_time": "2018-06-16T16:15:07.066321Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=[activation_block,tumortype_block,survival_block])\n",
    "model.load_weights(\"./weights/model_2_weights.h5\", by_name=True)\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=5e-4), \n",
    "              loss={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error', 'tumortype_block': 'binary_crossentropy'}, \n",
    "              loss_weights={'activation_block': 1., 'survival_block': 0.2, 'tumortype_block': 0.2},\n",
    "             metrics={'activation_block': ['accuracy',weighted_dice_coefficient, dice_coefficient], 'survival_block': ['accuracy', 'mae'], 'tumortype_block': ['accuracy']})\n",
    "\n",
    "model.summary(line_length=150) # add the parameter that allows me to show everything instead of cutting it off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the 3 prediction subset data net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:15:14.331Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = SubDataGenerator(subpartition['train'], **params)\n",
    "validation_generator = SubDataGenerator(subpartition['test'], **params)\n",
    "\n",
    "cb_1=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "cb_2=keras.callbacks.ModelCheckpoint(filepath=\"./weights/3pred_weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "results = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                   epochs=100, \n",
    "                   nb_worker=4,\n",
    "                   callbacks=[cb_1,cb_2])\n",
    "\n",
    "model.save_weights(\"./weights/model_3_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training history and predictions for 3 predictions (subset of data with survival predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3_pred = results.history\n",
    "pickle.dump( history_3_pred, open( \"./weights/history_3_pred.pkl\", \"wb\" ) )\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = SubDataGenerator(subpartition['holdout'], **params)\n",
    "\n",
    "predictions_3_pred = model.predict_generator(generator=validation_generator)\n",
    "\n",
    "pickle.dump( predictions_3_pred, open( \"./weights/predictions_3_pred.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set predictions for 2 predictions (all data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = DataGenerator(partition['holdout'], **params)\n",
    "\n",
    "prediction = model.predict_generator(generator=validation_generator)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set predictions for 3 predictions (subset of data with survival predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = SubDataGenerator(subpartition['holdout'], **params)\n",
    "\n",
    "prediction = model.predict_generator(generator=validation_generator)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check on the predictions:\n",
    "len(prediction)\n",
    "prediction[0].shape # segmentation mask\n",
    "prediction[1].shape # survival\n",
    "prediction[2].shape # tumor type\n",
    "# np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(completelist)\n",
    "len(set.intersection(set(HGG_dir_list), set(completelist)))\n",
    "len(set.intersection(set(LGG_dir_list), set(completelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ID in partition['holdout']:\n",
    "#     print(tumor_type_dict[ID])\n",
    "\n",
    "for ID in partition['holdout']:\n",
    "    print(tumor_type_dict[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir to_categorical_try\n",
    "# ! mkdir channel_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump( partition, open( \"./channel_split/partition.pkl\", \"wb\" ) ) # this has the test/train ID matches\n",
    "\n",
    "# # # access the test list:\n",
    "# # testIDlist = partition['test']\n",
    "# # testIDlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(prediction)):\n",
    "#     pickle.dump( prediction[i], open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "# # pickle.dump( model, open( \"model.pkl\", \"wb\" ) )\n",
    "# model.save_weights('./channel_split/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:08:23.123674Z",
     "start_time": "2018-06-19T03:08:23.119560Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "partition = pickle.load(open( \"./channel_split/partition.pkl\", \"rb\" ) ) # this has the test/train ID matches\n",
    "\n",
    "# access the test list:\n",
    "testIDlist = partition['test']\n",
    "# testIDlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T22:17:03.562719Z",
     "start_time": "2018-06-18T22:17:03.560118Z"
    }
   },
   "source": [
    "### Write images to .tif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imsave\n",
    "for i in range(len(prediction)):\n",
    "    imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "\n",
    "    imarray[]\n",
    "    imarray *= 255.0/imarray.max()\n",
    "    print(np.unique())\n",
    "    \n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"prediction.tif\", imarray)\n",
    "\n",
    "    # make ground truth \n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)         \n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5,160,192,160))\n",
    "    padded_image[:z.shape[0],:z.shape[1],:z.shape[2],:z.shape[3]] = z\n",
    "\n",
    "    a,b,c,d,seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a,b,c,d], axis=0)\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T22:45:15.378978Z",
     "start_time": "2018-06-18T22:45:14.073957Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "i = 0\n",
    "\n",
    "imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "# threshold the channels (for prediction):\n",
    "prediction_thresh = copy.deepcopy(imarray)\n",
    "prediction_thresh[prediction_thresh < 0.5] = 0.\n",
    "prediction_thresh[prediction_thresh >= 0.5] = 1.\n",
    "prediction_thresh = prediction_thresh\n",
    "print(np.unique(prediction_thresh))\n",
    "prediction_thresh *= 255.0/prediction_thresh.max() # convert to 8-bit pixel values\n",
    "prediction_thresh = prediction_thresh.astype(int)\n",
    "print(np.unique(prediction_thresh))\n",
    "print(prediction_thresh.shape)\n",
    "\n",
    "ID = testIDlist[i]\n",
    "img1 = './data/' + ID + '_flair.nii.gz'\n",
    "flairimg = nib.load(img1)\n",
    "flairimg = np.array(flairimg.dataobj)\n",
    "flairimg = np.expand_dims(flairimg, axis=0)\n",
    "flairimg = np.rollaxis(flairimg, 3, 0)\n",
    "print(np.unique(flairimg))\n",
    "flairimg = flairimg.astype(float)\n",
    "flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "flairimg = flairimg.astype(int)\n",
    "print(np.unique(flairimg))\n",
    "print(flairimg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making ground truth .tiff files: \n",
    "- Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:45:32.961094Z",
     "start_time": "2018-06-19T03:45:29.517419Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "from tifffile import imsave\n",
    "from libtiff import TIFF\n",
    "\n",
    "from skimage.io._plugins import freeimage_plugin as fi\n",
    "\n",
    "# import javabridge\n",
    "# import bioformats\n",
    "# javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "# your program goes here\n",
    "\n",
    "\n",
    "# ID = testIDlist[i]\n",
    "# for i in range(len(testIDlist)):\n",
    "for i in range(2):\n",
    "\n",
    "    print(\"current image:\", i)\n",
    "\n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)\n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5, 160, 192, 160))\n",
    "    padded_image[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "    a, b, c, d, seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a, b, c, d], axis=0)\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "    seg_mask_1 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_1[seg_mask.astype(int) > 0] = 1\n",
    "    seg_mask_2 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_2[seg_mask.astype(int) > 1] = 1\n",
    "    seg_mask_3 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_3[seg_mask.astype(int) > 2] = 1\n",
    "    seg_mask_3ch = np.concatenate(\n",
    "        [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "    # def scale_image(image_array):\n",
    "    #     image_array = image_array.astype(float)\n",
    "    #     image_array *= 255.0/image_array.max() # convert to 8-bit pixel values\n",
    "    #     image_array = image_array.astype(int)\n",
    "    #     return image_array\n",
    "\n",
    "    # img_array_list = [a,seg_mask_1,seg_mask_2,seg_mask_3]\n",
    "    # for img_array in img_array_list:\n",
    "    #     img_array = scale_image(img_array)\n",
    "\n",
    "    a = a.astype(float)\n",
    "    a *= 255.0/a.max()  # convert to 8-bit pixel values\n",
    "    a = np.rollaxis(a, 0, 2)\n",
    "    a = a.astype('uint8')\n",
    "#     print(\"unique flair values:\", np.unique(a))\n",
    "\n",
    "    seg_mask_1 = seg_mask_1.astype(float)\n",
    "    seg_mask_1 *= 255.0/seg_mask_1.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 2)\n",
    "    seg_mask_1 = seg_mask_1.astype('uint8')\n",
    "#     print(\"unique segment mask values:\", np.unique(seg_mask_1))\n",
    "\n",
    "    seg_mask_2 = seg_mask_2.astype(float)\n",
    "    seg_mask_2 *= 255.0/seg_mask_2.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 2)\n",
    "    seg_mask_2 = seg_mask_2.astype('uint8')\n",
    "\n",
    "    seg_mask_3 = seg_mask_3.astype(float)\n",
    "    seg_mask_3 *= 255.0/seg_mask_3.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 2)\n",
    "    seg_mask_3 = seg_mask_3.astype('uint8')\n",
    "\n",
    "#     ground_truth = np.concatenate(\n",
    "#         [a, seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype('uint8')\n",
    "\n",
    "#     print(\"unique flair + segment mask values:\", np.unique(ground_truth))\n",
    "    # shape.ground_truth\n",
    "    # flairimg = flairimg.astype(float)\n",
    "    # flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "    # flairimg = flairimg.astype(int)\n",
    "    # print(np.unique(flairimg))\n",
    "#     print(\"final image shape:\", ground_truth.shape)\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", ground_truth, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"flair.tif\", a, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_3.tif\", seg_mask_3, 'imagej')\n",
    "\n",
    "#     tiff = TIFF.open(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", mode='w')\n",
    "#     tiff.write_image(ground_truth)\n",
    "#     tiff.close()\n",
    "#     fi.write_multipage(ground_truth, \"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\")\n",
    "#     bioformats.write_image(pathname=\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", \n",
    "#                            pixels=ground_truth, \n",
    "#                            pixel_type=u'uint8',\n",
    "#                            size_c=4, size_z=160, size_t=1,\n",
    "#                            channel_names=None)\n",
    "\n",
    "# javabridge.kill_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T04:25:05.674829Z",
     "start_time": "2018-06-19T04:25:00.697594Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "from tifffile import imsave\n",
    "from libtiff import TIFF\n",
    "\n",
    "from skimage.io._plugins import freeimage_plugin as fi\n",
    "\n",
    "# import javabridge\n",
    "# import bioformats\n",
    "# javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "# your program goes here\n",
    "\n",
    "\n",
    "# ID = testIDlist[i]\n",
    "# for i in range(len(testIDlist)):\n",
    "for i in range(2):\n",
    "\n",
    "    print(\"current image:\", i)\n",
    "\n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)\n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5, 160, 192, 160))\n",
    "    padded_image[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "    a, b, c, d, seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a, b, c, d], axis=0)\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "    seg_mask_1 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_1[seg_mask.astype(int) > 0] = 1\n",
    "    seg_mask_2 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_2[seg_mask.astype(int) > 1] = 1\n",
    "    seg_mask_3 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_3[seg_mask.astype(int) > 2] = 1\n",
    "    seg_mask_3ch = np.concatenate(\n",
    "        [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "    # def scale_image(image_array):\n",
    "    #     image_array = image_array.astype(float)\n",
    "    #     image_array *= 255.0/image_array.max() # convert to 8-bit pixel values\n",
    "    #     image_array = image_array.astype(int)\n",
    "    #     return image_array\n",
    "\n",
    "    # img_array_list = [a,seg_mask_1,seg_mask_2,seg_mask_3]\n",
    "    # for img_array in img_array_list:\n",
    "    #     img_array = scale_image(img_array)\n",
    "\n",
    "    a = a.astype(float)\n",
    "    a *= 255.0/a.max()  # convert to 8-bit pixel values\n",
    "    a = np.rollaxis(a, 0, 2) # cxyz -> xycz for imagej\n",
    "    a = np.rollaxis(a, 0, 3) # switching x and z\n",
    "    a = a.astype('uint8')\n",
    "#     print(\"unique flair values:\", np.unique(a))\n",
    "\n",
    "    seg_mask_1 = seg_mask_1.astype(float)\n",
    "    seg_mask_1 *= 255.0/seg_mask_1.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 3) # switching x and z\n",
    "    seg_mask_1 = seg_mask_1.astype('uint8')\n",
    "#     print(\"unique segment mask values:\", np.unique(seg_mask_1))\n",
    "\n",
    "    seg_mask_2 = seg_mask_2.astype(float)\n",
    "    seg_mask_2 *= 255.0/seg_mask_2.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 3) # switching x and z\n",
    "    seg_mask_2 = seg_mask_2.astype('uint8')\n",
    "\n",
    "    seg_mask_3 = seg_mask_3.astype(float)\n",
    "    seg_mask_3 *= 255.0/seg_mask_3.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 3) # switching x and z\n",
    "    seg_mask_3 = seg_mask_3.astype('uint8')\n",
    "\n",
    "#     ground_truth = np.concatenate(\n",
    "#         [a, seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype('uint8')\n",
    "\n",
    "#     print(\"unique flair + segment mask values:\", np.unique(ground_truth))\n",
    "    # shape.ground_truth\n",
    "    # flairimg = flairimg.astype(float)\n",
    "    # flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "    # flairimg = flairimg.astype(int)\n",
    "    # print(np.unique(flairimg))\n",
    "#     print(\"final image shape:\", ground_truth.shape)\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", ground_truth, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_flair.tif\", a, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_3.tif\", seg_mask_3, 'imagej')\n",
    "\n",
    "    imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "\n",
    "    prediction_thresh = copy.deepcopy(imarray)\n",
    "    prediction_thresh[prediction_thresh < 0.5] = 0.\n",
    "    prediction_thresh[prediction_thresh >= 0.5] = 1.\n",
    "    prediction_thresh = prediction_thresh\n",
    "    print(np.unique(prediction_thresh))\n",
    "    prediction_thresh *= 255.0/prediction_thresh.max() # convert to 8-bit pixel values\n",
    "    prediction_thresh = prediction_thresh.astype('uint8')\n",
    "    prediction_thresh = np.rollaxis(prediction_thresh, 1, 3) # switching x and z; c will be taken care of in split\n",
    "    print(np.unique(prediction_thresh))\n",
    "    print(prediction_thresh.shape)\n",
    "\n",
    "    pred1, pred2, pred3 = np.split(prediction_thresh, 3, axis=0)\n",
    "\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_1.tif\", pred1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_2.tif\", pred2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_3.tif\", pred3, 'imagej')\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "\n",
    "\n",
    "    #     seg_mask_3ch = np.concatenate(\n",
    "#         [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "#     imarray *= 255.0/imarray.max()\n",
    "\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_3.tif\", seg_mask_3, 'imagej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
